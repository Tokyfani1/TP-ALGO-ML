{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N2Wn5DVqFrm6",
        "outputId": "d3862d15-16b1-4620-ccef-78890b213c5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemple de configuration gagnante :\n",
            "['W', 'W', '.']\n",
            "['W', 'W', '.']\n",
            "['.', '.', '.']\n",
            "\n",
            "Exemple de configuration perdante :\n",
            "['B', 'B', '.']\n",
            "['.', 'B', 'B']\n",
            "['.', '.', 'B']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "\n",
        "# Définir la taille du plateau (3x3)\n",
        "BOARD_SIZE = 3\n",
        "\n",
        "# Fonction pour générer une configuration aléatoire du plateau\n",
        "def generate_random_board():\n",
        "    return np.random.choice([-1, 0, 1], size=(BOARD_SIZE, BOARD_SIZE))\n",
        "\n",
        "# Fonction pour évaluer si une configuration est gagnante pour les blancs\n",
        "def is_winning_position(board):\n",
        "    white_count = np.sum(board == 1)\n",
        "    black_count = np.sum(board == -1)\n",
        "    return white_count >= 6 and white_count > black_count\n",
        "\n",
        "# Fonction pour évaluer si une configuration est perdante pour les blancs\n",
        "def is_losing_position(board):\n",
        "    white_count = np.sum(board == 1)\n",
        "    black_count = np.sum(board == -1)\n",
        "    return black_count >= 6 and black_count > white_count\n",
        "\n",
        "# Générer 500 configurations gagnantes pour les blancs\n",
        "winning_boards = []\n",
        "while len(winning_boards) < 500:\n",
        "    board = generate_random_board()\n",
        "    if is_winning_position(board):\n",
        "        winning_boards.append(board)\n",
        "\n",
        "# Générer 500 configurations perdantes pour les blancs\n",
        "losing_boards = []\n",
        "while len(losing_boards) < 500:\n",
        "    board = generate_random_board()\n",
        "    if is_losing_position(board):\n",
        "        losing_boards.append(board)\n",
        "\n",
        "# Créer un dataset avec les configurations et leurs labels\n",
        "X = np.array(winning_boards + losing_boards).reshape(-1, BOARD_SIZE * BOARD_SIZE)  # Aplatir les plateaux\n",
        "y = np.array([1] * 500 + [0] * 500)  # Labels : 1 pour gagnant, 0 pour perdant\n",
        "\n",
        "# Diviser le dataset en ensembles d'entraînement (80%) et de test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entraîner un modèle de régression multilinéaire\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "# Prédire avec le modèle de régression multilinéaire\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "# Convertir les prédictions continues en classes binaires (0 ou 1) avec un seuil de 0.5\n",
        "y_pred_linear_binary = (y_pred_linear >= 0.5).astype(int)\n",
        "\n",
        "# Entraîner un modèle de régression logistique\n",
        "logistic_model = LogisticRegression(random_state=42)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Prédire avec le modèle de régression logistique\n",
        "y_pred_logistic = logistic_model.predict(X_test)\n",
        "\n",
        "# Comparer les performances des deux modèles\n",
        "print(\"=== Régression Multilinéaire ===\")\n",
        "accuracy_linear = accuracy_score(y_test, y_pred_linear_binary)\n",
        "print(f\"Précision : {accuracy_linear:.2f}\")\n",
        "print(\"Rapport de classification :\")\n",
        "print(classification_report(y_test, y_pred_linear_binary))\n",
        "\n",
        "print(\"\\n=== Régression Logistique ===\")\n",
        "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
        "print(f\"Précision : {accuracy_logistic:.2f}\")\n",
        "print(\"Rapport de classification :\")\n",
        "print(classification_report(y_test, y_pred_logistic))\n",
        "\n",
        "# Comparer les erreurs quadratiques moyennes (MSE)\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "mse_logistic = mean_squared_error(y_test, y_pred_logistic)\n",
        "\n",
        "print(\"\\n=== Comparaison des Erreurs ===\")\n",
        "print(f\"MSE (Régression Multilinéaire) : {mse_linear:.4f}\")\n",
        "print(f\"MSE (Régression Logistique) : {mse_logistic:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKfBrWW2Ywpy",
        "outputId": "fba39835-3e7c-43bd-ecb2-7ef0970043a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Régression Multilinéaire ===\n",
            "Précision : 1.00\n",
            "Rapport de classification :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       104\n",
            "           1       1.00      1.00      1.00        96\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n",
            "\n",
            "=== Régression Logistique ===\n",
            "Précision : 1.00\n",
            "Rapport de classification :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       104\n",
            "           1       1.00      1.00      1.00        96\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n",
            "\n",
            "=== Comparaison des Erreurs ===\n",
            "MSE (Régression Multilinéaire) : 0.0121\n",
            "MSE (Régression Logistique) : 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparaison entre la regression multilinéaire et la régression logistique\n",
        "Explications du Code:\n",
        "\n",
        "Génération des Données :\n",
        "\n",
        "Nous générons 500 configurations gagnantes et 500 configurations perdantes pour les blancs, comme expliqué précédemment.\n",
        "\n",
        "Modèle de Régression Multilinéaire :\n",
        "\n",
        "Le modèle LinearRegression prédit une valeur continue entre 0 et 1.\n",
        "Les prédictions sont converties en classes binaires (0 ou 1) en appliquant un seuil de 0.5.\n",
        "\n",
        "Modèle de Régression Logistique :\n",
        "\n",
        "Le modèle LogisticRegression prédit directement une classe (0 ou 1).\n",
        "\n",
        "Évaluation des Modèles :\n",
        "La précision est calculée pour mesurer la performance des deux modèles.\n",
        "Le rapport de classification affiche des métriques supplémentaires comme le rappel et le F1-score.\n",
        "L'erreur quadratique moyenne (MSE) est utilisée pour comparer les erreurs des deux modèles.\n",
        "\n",
        "Résultats Attendus:\n",
        "\n",
        "Précision :\n",
        "La régression logistique devrait avoir une meilleure précision que la régression multilinéaire, car elle est spécifiquement conçue pour les problèmes de classification binaire.\n",
        "\n",
        "Exemple :\n",
        "\n",
        "Précision (Régression Multilinéaire) : 0.85\n",
        "\n",
        "Précision (Régression Logistique) : 0.95\n",
        "\n",
        "Erreur Quadratique Moyenne (MSE) :\n",
        "\n",
        "La régression logistique devrait avoir un MSE plus faible que la régression multilinéaire, car elle ajuste mieux les probabilités pour la classification.\n",
        "\n",
        "# Proposition d'amélioration de la qualité des modèles\n",
        "1. Amélioration des Caractéristiques (Feature Engineering)\n",
        "Les modèles actuels utilisent uniquement les valeurs brutes des cases du plateau comme entrée. Cependant, ces informations ne capturent pas toujours les relations stratégiques sous-jacentes dans le jeu. Pour capturer des signaux plus fins, nous pouvons ajouter des caractéristiques dérivées :\n",
        "\n",
        "Nombre de pions blancs/noirs :\n",
        "\n",
        "Ajouter des caractéristiques:\n",
        "telles que nombre_de_pions_blancs, nombre_de_pions_noirs, et leur différence.\n",
        "\n",
        "Contrôle local :\n",
        "\n",
        "Identifier les régions du plateau contrôlées par chaque joueur. Par exemple, si un joueur contrôle une ligne, une colonne, ou une diagonale.\n",
        "\n",
        "Possibilités de capture :\n",
        "\n",
        "Ajouter des indicateurs pour représenter les opportunités de capture pour chaque joueur. Par exemple, si un pion peut capturer un adversaire immédiatement.\n",
        "\n",
        "Distance aux objectifs stratégiques :\n",
        "\n",
        "Mesurer la distance entre les pions blancs et les zones clés du plateau où ils pourraient remporter la partie.\n",
        "\n",
        "Caractéristiques basées sur des motifs récurrents :\n",
        "\n",
        "Extraire des motifs spécifiques (par exemple, alignements partiels, configurations défensives) qui sont connus pour être avantageux ou désavantageux.\n",
        "\n",
        "Exemple d'ajout de caractéristiques :"
      ],
      "metadata": {
        "id": "GBOxuD7Rgbiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(board):\n",
        "    white_count = np.sum(board == 1)\n",
        "    black_count = np.sum(board == -1)\n",
        "    diff_count = white_count - black_count\n",
        "\n",
        "    # Ajouter des caractéristiques supplémentaires ici\n",
        "    features = [\n",
        "        white_count, black_count, diff_count,\n",
        "        # Exemple : Ajouter des indicateurs pour les lignes/columnes/diagonales contrôlées\n",
        "        int(np.any(np.all(board == 1, axis=0))),  # Ligne blanche complète ?\n",
        "        int(np.any(np.all(board == -1, axis=0)))  # Ligne noire complète ?\n",
        "    ]\n",
        "    return np.array(features)\n",
        "\n",
        "# Appliquer la fonction extract_features à chaque plateau\n",
        "X_train_features = np.array([extract_features(board) for board in X_train])\n",
        "X_test_features = np.array([extract_features(board) for board in X_test])"
      ],
      "metadata": {
        "id": "o-13CriIopVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZOYNeCYV4lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Augmentation des Données\n",
        "\n",
        "Les modèles peuvent manquer de généralisation si les données d'entraînement ne couvrent pas suffisamment de scénarios variés. Voici quelques techniques pour augmenter les données :\n",
        "\n",
        "Génération de nouvelles configurations :\n",
        "\n",
        "Générer davantage de plateaux avec des heuristiques plus complexes pour inclure des positions intermédiaires (\"presque gagnées\" ou \"presque perdues\").\n",
        "\n",
        "Transformation du plateau :\n",
        "\n",
        "Appliquer des rotations ou des symétries au plateau pour créer de nouvelles variations des mêmes positions. Cela permet d'augmenter artificiellement la taille du dataset.\n",
        "\n",
        "Exemple de transformation :"
      ],
      "metadata": {
        "id": "tzHUAZ0hoz4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(boards, labels):\n",
        "    augmented_boards = []\n",
        "    augmented_labels = []\n",
        "    for board, label in zip(boards, labels):\n",
        "        # Ajouter la configuration originale\n",
        "        augmented_boards.append(board)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        # Ajouter une rotation de 90°\n",
        "        rotated_board = np.rot90(board)\n",
        "        augmented_boards.append(rotated_board)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        # Ajouter une symétrie horizontale\n",
        "        flipped_board = np.fliplr(board)\n",
        "        augmented_boards.append(flipped_board)\n",
        "        augmented_labels.append(label)\n",
        "    return np.array(augmented_boards), np.array(augmented_labels)\n",
        "\n",
        "# Appliquer l'augmentation de données\n",
        "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)\n",
        "X_test_augmented, y_test_augmented = augment_data(X_test, y_test)"
      ],
      "metadata": {
        "id": "2UlBF6KEpDcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Utilisation de Modèles Plus Avancés\n",
        "\n",
        "Bien que les modèles linéaires (régression multilinéaire et logistique) soient simples et interprétables, ils peuvent ne pas capturer des relations non linéaires complexes. Voici des alternatives plus puissantes :\n",
        "\n",
        "a) Réseaux de Neurones Convolutifs (CNN)\n",
        "Les CNN sont particulièrement adaptés pour capturer des relations spatiales sur des grilles, comme celles présentes dans le Fanorona malgache.\n",
        "\n",
        "Exemple d'architecture CNN :\n"
      ],
      "metadata": {
        "id": "8ndd4e_gpPIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(BOARD_SIZE, BOARD_SIZE, 1)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Sortie binaire (0 ou 1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train.reshape(-1, BOARD_SIZE, BOARD_SIZE, 1), y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "IwozlJanpcg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Modèles Basés sur les Arbres de Décision\n",
        "\n",
        "Des modèles comme Random Forest ou Gradient Boosting peuvent capturer des interactions complexes entre les caractéristiques sans nécessiter une architecture complexe.\n",
        "\n",
        "Exemple avec Gradient Boosting :"
      ],
      "metadata": {
        "id": "ty2o1YH_pgDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "gb_model.fit(X_train_features, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test_features)\n",
        "print(f\"Précision (Gradient Boosting) : {accuracy_score(y_test, y_pred_gb):.2f}\")"
      ],
      "metadata": {
        "id": "sMfocSugpoTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Évaluation sur des Positions Intermédiaires\n",
        "\n",
        "Pour évaluer la capacité des modèles à détecter les positions \"presque gagnées\" ou \"presque perdues\", il est important de créer un ensemble de test spécifique contenant ces positions.\n",
        "\n",
        "Génération de positions intermédiaires :\n",
        "\n",
        "Créer des configurations où ni les blancs ni les noirs n'ont encore une victoire assurée, mais où l'un des joueurs a une légère avance.\n",
        "\n",
        "Métriques spécifiques :\n",
        "\n",
        "Utiliser des métriques comme la précision pondérée ou le F1-score pour évaluer la performance sur ces positions critiques.\n",
        "\n",
        "5. Apprentissage Renforcé (Reinforcement Learning)\n",
        "\n",
        "Pour capturer des stratégies plus avancées, on peut envisager des approches d'apprentissage par renforcement, où un agent apprend à jouer directement en interagissant avec l'environnement du jeu.\n",
        "\n",
        "Approche simplifiée :\n",
        "\n",
        "Entraîner un modèle pour prédire les mouvements optimaux à partir de positions donnés.\n",
        "Utiliser cet agent pour générer des positions \"presque gagnées\" ou \"presque perdues\".\n"
      ],
      "metadata": {
        "id": "lZwbw0oZpxf5"
      }
    }
  ]
}